<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Ray: 0.3 Release | Ray: A fast and simple framework for distributed applications</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Ray: 0.3 Release" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post announces the release of Ray 0.3." />
<meta property="og:description" content="This post announces the release of Ray 0.3." />
<link rel="canonical" href="/2017/11/30/ray-0.3-release.html" />
<meta property="og:url" content="/2017/11/30/ray-0.3-release.html" />
<meta property="og:site_name" content="Ray: A fast and simple framework for distributed applications" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-11-30T14:00:00+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"Ray: 0.3 Release","dateModified":"2017-11-30T14:00:00+00:00","url":"/2017/11/30/ray-0.3-release.html","datePublished":"2017-11-30T14:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2017/11/30/ray-0.3-release.html"},"description":"This post announces the release of Ray 0.3.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Ray: A fast and simple framework for distributed applications" /><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110413294-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110413294-2');
</script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Ray: A fast and simple framework for distributed applications</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Ray: 0.3 Release</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2017-11-30T14:00:00+00:00" itemprop="datePublished">Nov 30, 2017
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>We are pleased to announce the Ray 0.3 release. This release introduces
<a href="http://ray.readthedocs.io/en/latest/actors.html#passing-around-actor-handles-experimental"><strong>distributed actor handles</strong></a> and <a href="http://ray.readthedocs.io/en/latest/tune.html"><strong>Ray.tune</strong></a> — a new
hyperparameter search library. It also includes a number of bug fixes and
stability enhancements.</p>

<p>To upgrade to the latest version, run</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install -U ray
</code></pre></div></div>

<h2 id="hyperparameter-search-tool">Hyperparameter Search Tool</h2>

<p>This release adds <a href="http://ray.readthedocs.io/en/latest/tune.html"><strong>Ray.tune</strong></a>, a distributed hyperparameter evaluation
tool for long-running tasks such as reinforcement learning and deep learning
training. It currently includes the following features:</p>

<ul>
  <li>Pluggable <strong>early stopping algorithms</strong> including the Median Stopping Rule and
<a href="https://arxiv.org/abs/1603.06560">Hyperband</a>.</li>
  <li>Integration with <strong>visualization tools</strong> such as <a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">TensorBoard</a>,
<a href="https://media.readthedocs.org/pdf/rllab/latest/rllab.pdf">rllab’s VisKit</a>, and a <a href="https://en.wikipedia.org/wiki/Parallel_coordinates">parallel coordinates visualization</a>.</li>
  <li>Flexible <strong>trial variant generation</strong>, including grid search, random search,
and conditional parameter distributions.</li>
  <li><strong>Resource-aware scheduling</strong>, including support for concurrent runs of
algorithms that require GPUs or are themselves parallel and distributed.</li>
</ul>

<p>Ray.tune provides a Python API for use with deep learning and other compute
intensive training tasks. Here is a toy example illustrating usage.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">register_trainable</span><span class="p">,</span> <span class="n">grid_search</span><span class="p">,</span> <span class="n">run_experiments</span>

<span class="k">def</span> <span class="nf">my_func</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">reporter</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">time</span><span class="p">,</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">reporter</span><span class="p">(</span><span class="n">timesteps_total</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">mean_accuracy</span><span class="o">=</span><span class="n">i</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s">'alpha'</span><span class="p">])</span>

        <span class="n">i</span> <span class="o">+=</span> <span class="n">config</span><span class="p">[</span><span class="s">'beta'</span><span class="p">]</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">register_trainable</span><span class="p">(</span><span class="s">'my_func'</span><span class="p">,</span> <span class="n">my_func</span><span class="p">)</span>

<span class="n">run_experiments</span><span class="p">({</span>
    <span class="s">'my_experiment'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">'run'</span><span class="p">:</span> <span class="s">'my_func'</span><span class="p">,</span>
        <span class="s">'resources'</span><span class="p">:</span> <span class="p">{</span><span class="s">'cpu'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'gpu'</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
        <span class="s">'stop'</span><span class="p">:</span> <span class="p">{</span><span class="s">'mean_accuracy'</span><span class="p">:</span> <span class="mi">100</span><span class="p">},</span>
        <span class="s">'config'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">'alpha'</span><span class="p">:</span> <span class="n">grid_search</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]),</span>
            <span class="s">'beta'</span><span class="p">:</span> <span class="n">grid_search</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="p">})</span>
</code></pre></div></div>

<p>In-progress results can be visualized live using tools such as Tensorboard and
rllab’s VisKit (or you can read the JSON format logs directly from the driver
node):</p>

<p>View the <a href="http://ray.readthedocs.io/en/latest/tune.html">documentation</a> and the <a href="https://github.com/ray-project/ray/tree/master/python/ray/tune">code</a>.</p>

<h3 id="raytune-integration-with-rllib">Ray.tune integration with RLlib</h3>

<p>You can try out RLlib with Ray.tune with the following example.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>ray/python/ray/rllib
python train.py <span class="nt">-f</span> tuned_examples/cartpole-grid-search-example.yaml
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">tuned_examples</code> directory also contains pre-tuned hyperparameter
configurations for common benchmark tasks such as Pong and Humanoid. View the
<a href="http://ray.readthedocs.io/en/latest/rllib.html">RLlib documentation</a>.</p>

<h3 id="initial-support-for-pytorch-in-rllib">Initial Support for PyTorch in RLlib</h3>

<p>A modern reinforcement learning library should work with multiple deep learning
frameworks. As a step toward this goal, 0.3 adds support for PyTorch models for
A3C in RLlib. You can try this out with the following A3C config.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>ray/python/ray/rllib
./train.py <span class="nt">--run</span><span class="o">=</span>A3C <span class="se">\</span>
           <span class="nt">--env</span><span class="o">=</span>PongDeterministic-v4 <span class="se">\</span>
           <span class="nt">--config</span><span class="o">=</span><span class="s1">'{"use_pytorch": true, "num_workers": 8, "use_lstm": false, "model": {"grayscale": true, "zero_mean": false, "dim": 80, "channel_major": true}}'</span>
</code></pre></div></div>

<h2 id="distributed-actor-handles">Distributed Actor Handles</h2>

<p>Ray 0.3 adds support for <a href="http://ray.readthedocs.io/en/latest/actors.html#passing-around-actor-handles-experimental">distributed actor handles</a>, that is, the ability to
have multiple callers invoke methods on the same actor. The actor’s creator may
pass the actor handle as an argument to other tasks or to other actor methods.
Here’s an example in which the driver creates an actor to log messages and
passes an actor handle to other tasks:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">ray</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="o">@</span><span class="n">ray</span><span class="o">.</span><span class="n">remote</span>
<span class="k">class</span> <span class="nc">Logger</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">def</span> <span class="nf">log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_msg</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_msg</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">read_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">logs</span>

<span class="o">@</span><span class="n">ray</span><span class="o">.</span><span class="n">remote</span>
<span class="k">def</span> <span class="nf">task</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">task_index</span><span class="p">):</span>
    <span class="c1"># Do some work.
</span>    <span class="n">logged</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="s">'Task {} is done'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">task_index</span><span class="p">))</span>

<span class="c1"># Create an actor and get a handle to it.
</span><span class="n">logger</span> <span class="o">=</span> <span class="n">Logger</span><span class="o">.</span><span class="n">remote</span><span class="p">()</span>
<span class="c1"># Pass the actor handle to some tasks.
</span><span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">task</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="c1"># Wait for the tasks to finish.
</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tasks</span><span class="p">)</span>
<span class="c1"># Get the logs from the tasks.
</span><span class="k">print</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">logger</span><span class="o">.</span><span class="n">read_logs</span><span class="o">.</span><span class="n">remote</span><span class="p">()))</span>
</code></pre></div></div>

<p>This feature is still considered experimental, but we’ve already found
distributed actor handles useful for implementing <a href="http://ray.readthedocs.io/en/latest/example-parameter-server.html"><strong>parameter server</strong></a> and
<a href="http://ray.readthedocs.io/en/latest/example-streaming.html"><strong>streaming MapReduce</strong></a> applications.</p>


  </div><a class="u-url" href="/2017/11/30/ray-0.3-release.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ray: A fast and simple framework for distributed applications</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ray: A fast and simple framework for distributed applications</li><li><a class="u-email" href="mailto:"></a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ray-project"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ray-project</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Ray is a fast and simple framework for building and running distributed applications.
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
